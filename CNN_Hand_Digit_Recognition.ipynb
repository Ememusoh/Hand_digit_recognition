{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Tensorflow implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the data\n",
    "\n",
    "(X,Y), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28)\n",
      "(48000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n",
      "(12000, 28, 28)\n",
      "(12000,)\n"
     ]
    }
   ],
   "source": [
    "## split the (X,Y) into train and val set\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X,Y, test_size= 0.2)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "(12000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "## we have to convert it to a format that the convolution network (3 dimension)\n",
    "\n",
    "x_train = x_train[:, :, :, np.newaxis]\n",
    "x_test = x_test[:,:,:, np.newaxis]\n",
    "x_val = x_val[:,:,:, np.newaxis]\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(x_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we have to normalise the data from between 0-1 (2**8 - 1 == 255)\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0\n",
    "x_val = x_val/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### construct the model architecture\n",
    "\n",
    "input_to_model = tf.keras.layers.Input(shape = (28,28,1), name = \"input_layer\")\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), strides = 2, padding = \"same\", activation= \"relu\")(input_to_model)\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, strides = 2, padding= \"same\", activation= \"relu\" )(x)\n",
    "x = tf.keras.layers.Conv2D(filters= 128, kernel_size = 3, strides = 2, padding= \"same\", activation= \"relu\")(x)\n",
    "\n",
    "#we have to flatten it so that we can input into the neural network\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "## construct the neural network and feed the flatten input into each neurons\n",
    "x = tf.keras.layers.Dense(256, activation= \"relu\")(x)\n",
    "x = tf.keras.layers.Dense(512, activation= \"relu\")(x)\n",
    "\n",
    "## since we are expecting 10 classification (0-9)\n",
    "## softmax cause it is classification\n",
    "## 10 because we are expecting 10 output\n",
    "## no activation for regression\n",
    "\n",
    "output = tf.keras.layers.Dense(10, activation= \"softmax\", name = \"output_layer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               524544    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 753,930\n",
      "Trainable params: 753,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "output.shape\n",
    "\n",
    "model = tf.keras.Model(inputs = input_to_model, outputs = output )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we have to get the optimizer and the loss, metric for classification\n",
    "model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=1e-3), loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 27s 18ms/step - loss: 2.3015 - accuracy: 0.1119 - val_loss: 2.3009 - val_accuracy: 0.1143\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 53s 35ms/step - loss: 2.3015 - accuracy: 0.1119 - val_loss: 2.3008 - val_accuracy: 0.1143\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 55s 37ms/step - loss: 2.3015 - accuracy: 0.1119 - val_loss: 2.3008 - val_accuracy: 0.1143\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 57s 38ms/step - loss: 2.3015 - accuracy: 0.1119 - val_loss: 2.3007 - val_accuracy: 0.1143\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 54s 36ms/step - loss: 2.3014 - accuracy: 0.1119 - val_loss: 2.3009 - val_accuracy: 0.1143\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 56s 37ms/step - loss: 2.3015 - accuracy: 0.1119 - val_loss: 2.3007 - val_accuracy: 0.1143\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 57s 38ms/step - loss: 2.3015 - accuracy: 0.1119 - val_loss: 2.3008 - val_accuracy: 0.1143\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 56s 37ms/step - loss: 2.3015 - accuracy: 0.1119 - val_loss: 2.3009 - val_accuracy: 0.1143\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 55s 37ms/step - loss: 2.3015 - accuracy: 0.1119 - val_loss: 2.3010 - val_accuracy: 0.1143\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 56s 37ms/step - loss: 2.3014 - accuracy: 0.1119 - val_loss: 2.3009 - val_accuracy: 0.1143\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 55s 37ms/step - loss: 2.3015 - accuracy: 0.1119 - val_loss: 2.3007 - val_accuracy: 0.1143\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 55s 37ms/step - loss: 2.3015 - accuracy: 0.1119 - val_loss: 2.3010 - val_accuracy: 0.1143\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 55s 37ms/step - loss: 2.3014 - accuracy: 0.1119 - val_loss: 2.3011 - val_accuracy: 0.1143\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 57s 38ms/step - loss: 2.3015 - accuracy: 0.1119 - val_loss: 2.3008 - val_accuracy: 0.1143\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 56s 37ms/step - loss: 2.3015 - accuracy: 0.1119 - val_loss: 2.3011 - val_accuracy: 0.1143\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 55s 37ms/step - loss: 2.3015 - accuracy: 0.1119 - val_loss: 2.3009 - val_accuracy: 0.1143\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 56s 37ms/step - loss: 2.3015 - accuracy: 0.1119 - val_loss: 2.3010 - val_accuracy: 0.1143\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 57s 38ms/step - loss: 2.3015 - accuracy: 0.1119 - val_loss: 2.3009 - val_accuracy: 0.1143\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 2.3015 - accuracy: 0.1119"
     ]
    }
   ],
   "source": [
    "#we train the data and test the validation data\n",
    "model_history = model.fit(x = x_train, y = y_train, validation_data=(x_val, y_val), batch_size= 32, epochs= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 12ms/step - loss: 2.3010 - accuracy: 0.1135\n"
     ]
    }
   ],
   "source": [
    "## evalution of test set\n",
    "\n",
    "test_score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provides the dictionary for visualization\n",
    "model_history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(model_history.history)\n",
    "\n",
    "df.plot()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to save the model\n",
    "# model.save(\"Hand_digit_model.h5\")\n",
    "\n",
    "\n",
    "## load data\n",
    "# model = tf.keras.models.load_model(\"Hand_digit_model.h5\")\n",
    "\n",
    "\n",
    "##predict\n",
    "\n",
    "# ypred = model.predict(x_test)\n",
    "#ypred[0]\n",
    "\n",
    "#plt.imshow(x_test[0])\n",
    "##y comes in an array and the max(highest) prob is the one that is most likely  \n",
    "#ypred = np.argmax(ypred, axis = 1) \n",
    "#ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "test_acc = round(accuracy_score(y_test, ypred),3)\n",
    "test_pre = round(precision_score(y_test, ypred, average=\"weighted\"),3)\n",
    "test_rec = round(recall_score(y_test, ypred, average=\"weighted\"),3)\n",
    "\n",
    "print(test_acc)\n",
    "print(test_pre)\n",
    "print(test_rec)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, ypred, labels= [0,1,2,3,4,5,6,7,8,9])\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2,3,4,5,6,7,8,9])\n",
    "disp.plot()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
